\chapter{Principles of Artificial Neural Networks}

The term "artificial neural networks" denominates a set of heuristic and metaheuristic algorithms using directed graph data structures to provide solutions for problems which can be resolved through learning processes. Since neural networks are based on directed graphs, they posess nodes and edges which analogously to the anatomy of a biological brain are referred to as neurons and synapses. These two components satisfy the following conditions:
\begin{description}
\item[$\bullet$] Neurons can be ordered into layers.
\item[$\bullet$] Each layer can have a different number of neurons.
\item[$\bullet$] Each neuron has its own weight and outgoing synapses that feed into a neuron of the next layer.
\item[$\bullet$] Given two adjacent layers a \& b, each neuron of layer a is connected to all neurons of layer b and vice versa. 
\item[$\bullet$] Each neuron not contained in the first layer of the graph is associated with multiple biases towards synapses which feed into itself.
\item[$\bullet$] Each synapse has its own weight.
\end{description}
The weights in a neural Network might not exclusively hold numerical values, as can be demonstrated in binarized neural networks.         
\section{Machine Learning}

\Blindtext[4][1]

\section{Deep Learning}

\Blindtext[4][1]
