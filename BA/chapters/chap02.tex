\chapter{Principles of Artificial Neural Networks}
\section{Popular Mathematical Representational Models for ANNs}
\subsection{Architecture of Anns}
The term "artificial neural networks" denominates a set of heuristic and metaheuristic algorithms using directed graph data structures to provide solutions for problems which can be resolved through learning processes. Since neural networks are based on directed graphs, they posess nodes and edges which, analogously to the anatomy of a biological brain, are referred to as neurons and synapses. The architecture of a neural network will vary depending on its designation.
\subsection{Data Processing Strategies in ANNs}
\subsection{Learning Processes in Neural Networks}
Untrained neural networks will not perform accurately and they require pre-classified sample subjects to be able discern between new input values. With these pre-classified values one can change the configuration of a neural network to enhance its classification capabilities by feeding the neural network with an error function which calculates how accurately the data set has been classified. Knowing the error, one can continue adjusting the weights and biases of the synapses and neurons in the network so that the error function outputs a lower value. 
The problem of lowering the error rate of a function based on predefined criteria is analogous to finding local minima in a multi-dimensional function.
\section{Deep Neural Networks}        
 %These two components satisfy the following conditions:
%\begin{description}
%\item[$\bullet$] Neurons can be ordered into layers.
%\item[$\bullet$] Each layer can have a different number of neurons.
%\item[$\bullet$] Each neuron but the last has outgoing synapses
%\item[$\bullet$] Given two adjacent layers a \& b, each neuron of layer a is connected to all neurons of layer b and vice versa. 
%\item[$\bullet$] Each neuron not contained in the first layer of the graph is associated with multiple biases towards synapses which feed into itself.
%\item[$\bullet$] Each synapse has its own weight.
%\end{description}
%The weights in a neural Network might not exclusively hold numerical values, as can be %demonstrated in binarized neural networks.
  


\Blindtext[4][1]

\section{Deep Learning}
\Blindtext[4][1]
